{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853bbbdd-813c-430a-b6f7-101b5f480b85",
   "metadata": {},
   "source": [
    "# Chapter #3: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8da3585-a6be-4acd-85b8-db05bfe390fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb1690-3faa-411a-8211-1121a72aaa57",
   "metadata": {},
   "source": [
    "## 1. The problems with holdout sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa35bc3-7889-40e8-b204-a1b2fa048239",
   "metadata": {},
   "source": [
    "1. The problems with holdout sets\n",
    "> Hello again - let's continue our quest for validating machine learning models by discussing why traditional validation approaches still have pitfalls.\n",
    "\n",
    "2. Transition validation\n",
    "> The typical modeling procedure looks something like this. We take a dataset, use, say, 80% for training, and the remaining 20% for testing. We learned how to do this a couple lessons ago using scikit-learn. Using the train_test_split() function, we split our data and run a random forest classifier on this single split for our model. Here we have output the MAE, and the error was 10-point-24.\n",
    "\n",
    "3. Traditional training splits\n",
    "> If we repeat this process with a different random seed though, we might get different results. Consider the following two samples from the ultimate candy-power-ranking dataset: s1 and s2. This dataset consists of 85 data points about candy characteristics, and we have randomly selected 60 candies for each sample. Only 39 of the 60 candies overlap between the two datasets.\n",
    "\n",
    "4. Traditional training splits\n",
    "> Furthermore, the first sample contains 34 chocolate candies, and the second sample only contains 30.\n",
    "\n",
    "5. The split matters\n",
    "> Why is this important? Well, we have already seen that selecting 60 candies for a sample can be highly variable. If we split the candy dataset into 60 candies for training and 25 candies for testing, and build the exact same machine learning model, we'll probably get slightly varying results. In this example alone, the second testing accuracy is over 12% worse. Using the first sample, you would report an error of 10-point-32. The second gives an error of 11-point-56. These results are way too different.\n",
    "\n",
    "6. Train, validation, test\n",
    "> Even the train, validation, test procedure we discussed earlier is not safe from the problems we could have with holdout samples, especially when we have limited data. Consider this example. We created a train, test, and validation split. We fit a random forest model, and maybe we even did some hyperparameter tuning or testing of various models. In the end, we decided on this random forest regressor model. Look at how close the validation and testing accuracies are to each other - 9-point-18 and 8-point-98. This is awesome, right?\n",
    "\n",
    "7. Round 2\n",
    "> Let's run the same model again, but this time we will run it with a different random seed. The errors were 8-point-73 and 10-point-91, which is a big problem. This can happen when using the traditional validation approach, especially with limited data. We think our model is validated, but if we just changed the sample we used - we get drastically different results. This random forest model with only 25 trees and 4 features does not seem to generalize as well to new data as we would expect.\n",
    "\n",
    "8. Holdout set exercises\n",
    "> To overcome this limitation of holdout sets, we use something called cross-validation, which is the gold-standard for model validation! Before we fully introduce cross-validation, let's discover why we need it with a couple of exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c5dad-aa5f-44d7-9b00-cf2ca8bfd681",
   "metadata": {},
   "source": [
    "### 1.1. Two samples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b053d-725a-4eeb-990b-cdbc5a5c582c",
   "metadata": {},
   "source": [
    "After building several classification models based on `thetic_tac_toe` dataset, you realize that some models do not generalize as well as others. You have created training and testing splits just as you have been taught, so you are curious why your validation process is not working.\n",
    "\n",
    "After trying a different training, test split, you noticed differing accuracies for your machine learning model. Before getting too frustrated with the varying results, you have decided to see what else could be going on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1897b1-9620-4569-939a-059817ba8b0f",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e694e9f-c415-41c2-9880-9ec3258ec573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data:\n",
    "tic_tac_toe = pd.read_csv(\"./data/tic-tac-toe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc966be8-ce08-470a-98f7-736a40552bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data shape:\n",
    "tic_tac_toe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f5d4fc-217d-4173-9934-68c91b95e2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-Left</th>\n",
       "      <th>Top-Middle</th>\n",
       "      <th>Top-Right</th>\n",
       "      <th>Middle-Left</th>\n",
       "      <th>Middle-Middle</th>\n",
       "      <th>Middle-Right</th>\n",
       "      <th>Bottom-Left</th>\n",
       "      <th>Bottom-Middle</th>\n",
       "      <th>Bottom-Right</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n",
       "0        x          x         x           x             o            o   \n",
       "1        x          x         x           x             o            o   \n",
       "2        x          x         x           x             o            o   \n",
       "3        x          x         x           x             o            o   \n",
       "4        x          x         x           x             o            o   \n",
       "\n",
       "  Bottom-Left Bottom-Middle Bottom-Right     Class  \n",
       "0           x             o            o  positive  \n",
       "1           o             x            o  positive  \n",
       "2           o             o            x  positive  \n",
       "3           o             b            b  positive  \n",
       "4           b             o            b  positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the first 5 rows:\n",
    "tic_tac_toe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcebd8ff-81df-44eb-b497-e7652737f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the target column into (0 / 1):\n",
    "tic_tac_toe['Class'] = tic_tac_toe['Class'].apply(lambda x : 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772a76f7-3ce1-4ed5-affa-162a2ba67f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the feaatures into (0 / 1):\n",
    "features = [col for col in tic_tac_toe.columns if col != 'Class']\n",
    "tic_tac_toe = pd.get_dummies(data=tic_tac_toe, columns=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73761038-51db-4b80-ae0b-2c1656c14ff0",
   "metadata": {},
   "source": [
    "- Create samples `sample1` and `sample2` with 200 observations that could act as possible testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c4bf117-045c-4425-901e-06a79af82b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 different samples with 2 different seeds:\n",
    "sample1 = tic_tac_toe.sample(n=200, random_state=1111)\n",
    "sample2 = tic_tac_toe.sample(n=200, random_state=1171)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d405a-612f-489b-9adb-c6bfdf3f7c68",
   "metadata": {},
   "source": [
    "- Use the list comprehension statement to find out how many observations these samples have in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a3abf8-cb91-4462-8879-a2dc40854682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting how many common observations by list comprehension:\n",
    "len([idx for idx in sample1.index if idx in sample2.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ef56ed-ef03-42b4-8a07-f45016400486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we could do it this way:\n",
    "len(sample1.index.intersection(sample2.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b7290-6456-4f0b-b1c3-1372e3da7470",
   "metadata": {},
   "source": [
    "- Use the Series.value_counts() method to print the values in both samples for column Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa1251b-45b2-4f23-ae69-f3231f8c5971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample #1:\n",
      "1    134\n",
      "0     66\n",
      "Name: Class, dtype: int64\n",
      "Sample #2:\n",
      "1    123\n",
      "0     77\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Counting the frequency of values in the target column for both samples:\n",
    "print(f\"Sample #1:\\n{sample1['Class'].value_counts()}\")\n",
    "print(f\"Sample #2:\\n{sample2['Class'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584b8ff-ee88-48ad-bbdb-d0fbeb7c4d22",
   "metadata": {},
   "source": [
    "### 1.2. Potential problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd984953-9c43-4e9a-954c-088572228527",
   "metadata": {},
   "source": [
    "Which of the following statements are TRUE regarding potential problems with holdout samples:\n",
    "\n",
    "> - A: Using different data splitting methods may lead to varying data in the final holdout samples.\n",
    "> - B: If you have limited data, your holdout accuracy may be misleading.\n",
    "> - C: There are no problems. Creating a single train and test sample is the only way to validate models.\n",
    "> - D: You shouldn't use holdout samples with limited data because you are limiting the potential training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f555022-e3ae-4d08-b740-9e149de1442b",
   "metadata": {},
   "source": [
    "Possible Answers:\n",
    "- A & D.\n",
    "- C & D.\n",
    "- A & B.\n",
    "- A, B, & D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23234-5feb-4c2d-9fc1-017f4bbbe056",
   "metadata": {},
   "source": [
    "> A & B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0be235-71e3-4fa8-968b-60e9faff5d31",
   "metadata": {},
   "source": [
    "## 2. Cross-validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14caa73-3d0f-4fd7-b821-3a0b6f76b59d",
   "metadata": {},
   "source": [
    "1. Cross-validation\n",
    "> Hello everyone - let's push validation a step further and discuss the gold-standard: cross-validation.\n",
    "\n",
    "2. Cross-validation\n",
    "> Before, we talked about using 80% of our data for training and 20% for testing. We took this a step further by splitting the 80% of training data into training and validation splits. Previously, we learned that our accuracy metric on this validation set may be misleading, or if we split this data differently, we might get different results.\n",
    "\n",
    "3. Cross-validation\n",
    "> For cross-validation we don't just need one of these training/validation splits— we need a bunch of them. This method makes us run our single model on various training/validation combinations and gives us a lot more confidence in our final metrics. For this example, we have a 5-fold cross-validation. Each time we run the model, a different 80% of the data will be used for training, and a different 20% will be used for validation. And we can do this in such a manner that all of the data will be used in only one of the validation sets. This ensures that every point is used for validation exactly one time. Although using each point in only one validation set is not required for cross-validation, it is often good practice to do so. And fortunately for us, this concept of what this should look like, how this could be done, and why it's even important is the hardest part. Actually implementing this is very straightforward.\n",
    "\n",
    "4. KFold cross-validation with scikit-learn\n",
    "> scikit-learn's KFold() function gives us a few options for splitting data into several training and validation sets. We can specify the number of splits that we want; we can specify if the data needs to be shuffled and to replicate our results, we can specify a random state. Here I have generated two arrays to use as data. The X array consists of the numbers 0 through 39, and the y array consists of 20 zeros followed by 20 ones. Next, we create the generator kf, which will split our data. It uses the KFold() function with five splits and no shuffling. To actually split our data, we call kf-dot-split() on X. This only generates indices for us to use. So I don't want you to think that we have generated five training and validation datasets. All we have done is created a list of indices, that can be used for our splits.\n",
    "\n",
    "5. Accessing indices\n",
    "> So what's actually in splits if it doesn't contain datasets? The splits variable contains the training and validation indices for the five different splits of X. If we print the length of the indices, we see train_index has 32 values, and test_index has eight values, and this is repeated five times. If we print out what these lists actually look like, we see train_index has the numbers 0 through 31, and test_index has the numbers 32 through 39. Calling these indices on X and y will give us training and validation data.\n",
    "\n",
    "6. Example using splits\n",
    "> KFold is generally used when we want to fit the same model using KFold cross-validation. We would create the splits, using kf.split(). We would then loop through the train and validation indices, and fit the same model using the new training data. Finally, we create the predictions and keep track of the errors. To see how well the model performed across the five splits that we created, we can look at the mean of the final error scores.\n",
    "\n",
    "7. Practice time\n",
    "> Let's get started and fold some data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646f67d-e931-41a9-98eb-1d22f2ebb67e",
   "metadata": {},
   "source": [
    "### 2.1. scikit-learn's KFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fff2dc-8f38-4e0c-add7-6860de6fdee8",
   "metadata": {},
   "source": [
    "You just finished running a colleagues code that creates a random forest model and calculates an out-of-sample accuracy. You noticed that your colleague's code did not have a random state, and the errors you found were completely different than the errors your colleague reported.\n",
    "\n",
    "To get a better estimate for how accurate this random forest model will be on new data, you have decided to generate some indices to use for KFold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa761f-5f55-4a6e-8dc8-5f23b15e2622",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f3d033d-7336-4018-8fc7-35f7f494c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data:\n",
    "candy = pd.read_csv(\"./data/candy-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f35a18e-17a5-4868-a995-0a071e159d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data shape:\n",
    "candy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a6cc78-d381-4562-95ed-3dca77eebb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  \n",
       "0   66.971725  \n",
       "1   67.602936  \n",
       "2   32.261086  \n",
       "3   46.116505  \n",
       "4   52.341465  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the first 5 rows:\n",
    "candy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c58668ac-14d8-41f8-a152-a0f08c1bfbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the first column:\n",
    "candy.drop(columns='competitorname', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c85ee4-54b6-475c-a929-53135486078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to split the data into X & y:\n",
    "def split_data(data, y_col):\n",
    "    \n",
    "    features = [col for col in data.columns if col != y_col]\n",
    "    \n",
    "    X = data[features].copy()\n",
    "    y = data[y_col].copy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7b64e22-8b5a-4d81-ac38-fee96e3c35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into feature matrix (X) & target column (y):\n",
    "X, y = split_data(candy, 'winpercent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6415aaf-5acd-404d-8c58-8b8041085349",
   "metadata": {},
   "source": [
    "- Call the `KFold()` method to split data using five splits, shuffling, and a random state of 1111."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36bd9af-34dc-45fd-95e3-e8a1074686f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a kfold object:\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ebad71-389e-4c12-9ca5-eeda2b6aa199",
   "metadata": {},
   "source": [
    "- Use the `split()` method of `KFold` on `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5e9fa94-296b-4baf-8ccc-567bd2cc506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a generator for splitting the data:\n",
    "splits = kf.split(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2463e45-a107-4480-b4fe-57be459902b2",
   "metadata": {},
   "source": [
    "- Print the number of indices in both the train and validation indices lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6258285-26ff-4e60-b0f0-0a45c82c8891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n"
     ]
    }
   ],
   "source": [
    "# Exploring the length of generated arrays of indices:\n",
    "for train_idx, val_idx in splits:\n",
    "    print(f\"Number of training indices: {len(train_idx)}\")\n",
    "    print(f\"Number of validation indices: {len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd5247-4150-41df-845a-659d916f440c",
   "metadata": {},
   "source": [
    "### 2.2. Using KFold indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08548c8-84de-4eb3-a1dc-8f0faa29e987",
   "metadata": {},
   "source": [
    "You have already created `splits`, which contains indices for the candy-data dataset to complete 5-fold cross-validation. To get a better estimate for how well a colleague's random forest model will perform on a new data, you want to run this model on the five different training and validation indices you just created.\n",
    "\n",
    "In this exercise, you will use these indices to check the accuracy of this model using the five different splits. A for loop has been provided to assist with this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061d600-ee9f-47f3-8379-01df16e92262",
   "metadata": {},
   "source": [
    "- Use `train_idx` and `val_idx` to call the correct indices of `X` and `y` when creating training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e263716-433a-4ff9-8718-6c9dfd78a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the model:\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f3918-6634-4741-a428-eb9c3d828c47",
   "metadata": {},
   "source": [
    "- Fit `rfr` using the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bdd1c-e4a7-40b5-a39b-9c01cf2c70a6",
   "metadata": {},
   "source": [
    "- Use `rfr` to create predictions for validation dataset and print the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8da33797-9830-40da-a980-6fa670117a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_idx, val_idx in splits:\n",
    "    \n",
    "#     # Setting the training & validation datasets:\n",
    "#     X_train, y_train = X[train_idx], y[train_idx]\n",
    "#     X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "#     # Fitting the model:\n",
    "#     y_pred = rfr.fit(X_train, y_train).predict(X_val)\n",
    "      \n",
    "#     # Evaluating performance:\n",
    "#     print(f\"Error: {mse(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bac875-c3f4-4107-a2cf-e8b56b381382",
   "metadata": {},
   "source": [
    "> there was a problem with this code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea695c0-54ee-46cc-8948-975856da0105",
   "metadata": {},
   "source": [
    "## 3. sklearn's cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712173f-65f8-44e5-add6-fa3899a25e78",
   "metadata": {},
   "source": [
    "1. sklearn's cross_val_score()\n",
    "> Hello again. Next, we are going to discuss cross-validation in scikit-learn.\n",
    "\n",
    "2. cross_val_score()\n",
    "> We have seen that KFold() is a great way to create indices that we can use for cross-validation. If you just want to jump straight into cross-validation and don't want to mess with the indices, you can use scikit-learn's cross_val_score() method. This method requires four parameters. First, we have the estimator or the specific model that you want to use. In this example, we have a RandomForestClassifier() with the default model settings. Next, we use X to specify the complete training dataset and y to specify the response values. Lastly, the parameter cv allows us to specify the number of cross-validation splits (or folds). In this example, we have set the parameter cv to 5, allowing us to perform 5-fold cross-validation. By default, cross_val_score() will use a default scoring function for whichever model you have specified. For example, if you have a RandomForestClassifer as the estimator, the default scoring function is the mean overall accuracy. For most regression models, it will return the R-squared value.\n",
    "\n",
    "3. Using scoring and make_scorer\n",
    "> If you want to use a different scoring function, you can create a scorer by using the make_scorer() method, and specifying the scoring metric that you want to use. Here we create a scorer for the mean_absolute_error() function by calling make_scorer() on scikit-learn's method for calculating the mean absolute error. Finally, we set the scoring parameter equal to the newly created mae_scorer inside the function.\n",
    "\n",
    "4. Full example\n",
    "> Let's run through a full example of using scikit-learn's cross_val_score() for a regression model. The first step is to load all of the necessary methods. We load the model, cross_val_score(), and both the make_scorer() and mean_squared_error() methods. Next, we specify the regression model we want to use, with the specific parameters, as well as create the scorer that should be used when running the regression model. Finally, we call cross_val_score() on the estimator, rfr, the dataset X, the response values y, and set scoring equal to the scorer we generated. In this example, we set cv to 5 to complete 5-fold cross-validation.\n",
    "\n",
    "5. Accessing the results\n",
    "> Let's look at the results. Notice how varied the mean squared errors are. The lowest was almost 86, while the highest was well over 200. If we have chosen an 80/20 split on the data at random, we may have reported an error as low as 86, or an error as high as 223. When we use cross-validation, we usually report the mean of the errors. In this case, it was 150. This is a much more realistic estimate for the out-of-sample accuracy that we can expect to see on new data. Eighty-six was probably way too low of an error, while 223 was way too high. Finally, we can look at the standard deviation to see how varied the five results were. The smaller the standard deviation, the tighter your 5 means were. This indicates that the actual accuracy for new data will probably match the mean of the cross-validation score fairly well.\n",
    "\n",
    "6. Let's practice!\n",
    "> Let's now use cross_val_score() to perform cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36164380-b54a-4fe5-b559-85bc0dc05abf",
   "metadata": {},
   "source": [
    "### 3.1. scikit-learn's methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a4d57-fd45-47ce-ae7f-7ea40414fd38",
   "metadata": {},
   "source": [
    "You have decided to build a regression model to predict the number of new employees your company will successfully hire next month. You open up a new Python script to get started, but you quickly realize that `sklearn` has a lot of different modules. Let's make sure you understand the names of the modules, the methods, and which module contains which method.\n",
    "\n",
    "Follow the instructions below to load in all of the necessary methods for completing cross-validation using `sklearn`. You will use modules:\n",
    "\n",
    "> - `metrics`\n",
    "> - `model_selection`\n",
    "> - `ensemble`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1445ee77-b571-4a4b-80e4-382bdc96adf4",
   "metadata": {},
   "source": [
    "- Load the method for calculating the scores of cross-validation.\n",
    "- Load the random forest regression method.\n",
    "- Load the mean square error metric.\n",
    "- Load the method for creating a scorer to use with cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d9ddb-d456-4494-8590-bba397d0921b",
   "metadata": {},
   "source": [
    "> Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4ae95-5a4e-413f-8985-7ed60032d98b",
   "metadata": {},
   "source": [
    "### 3.2. Implement cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad6d57-9375-4496-a013-4981d6d7e3e9",
   "metadata": {},
   "source": [
    "Your company has created several new candies to sell, but they are not sure if they should release all five of them. To predict the popularity of these new candies, you have been asked to build a regression model using the `candy` dataset. Remember that the response value is a head-to-head win-percentage against other candies.\n",
    "\n",
    "Before you begin trying different regression models, you have decided to run cross-validation on a simple random forest model to get a baseline error to compare with any future results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b4c8c-228c-4693-b05b-e952c706d555",
   "metadata": {},
   "source": [
    "- Fill in cross_val_score().\n",
    "> - Use `X_train` for the training data, and `y_train` for the response.\n",
    "> - Use `rfr` as the model, 10-fold cross-validation, and `mse` for the scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b27b341-4db7-46f8-8149-baf9fbf0ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model:\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e52ddc-620d-4b92-a2c5-c72f8d5414ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scoring startegy:\n",
    "scorer = make_scorer(mse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e0fe450-6607-4596-83d5-718fa7c6adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing 10-fold cross-validation:\n",
    "cv = cross_val_score(estimator=rfr, X=X, y=y , cv=10, scoring=scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68e751-7154-4b3a-9417-e08cb4b32a37",
   "metadata": {},
   "source": [
    "- Print the mean of the `cv` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddd65029-1050-4e9c-92f7-e57432c8a6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-155.4061992697056\n"
     ]
    }
   ],
   "source": [
    "# Printing the mean of cross-validation scores:\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae2366-aafe-41a2-b5a7-1d7bc6f16804",
   "metadata": {},
   "source": [
    "## 4. Leave-one-out-cross-validation (LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770aa8e4-795f-4825-8e9b-643a9d49f380",
   "metadata": {},
   "source": [
    "1. Leave-one-out-cross-validation (LOOCV)\n",
    "> Welcome back - in this lesson we take KFold cross-validation another step forward and discuss leave-one-out-cross-validation.\n",
    "\n",
    "2. LOOCV\n",
    "> The name says it all. In leave-one-out-cross-validation, we are going to implement KFold cross-validation, where k is equal to n, the number of observations in the data. This means that every single point will be used in a validation set, completely by itself. For the first model, we will use all of the data for training, except for the first point, which will be used for validation. In model 2, we leave only the second data point out, in model three, the third data point, and so on. We create n models, for n-observations in the data. It might seem odd to use a single point as a complete validation set, but recall what you will do after leave-one-out-cross-validation is complete. You will present the average error of the n model runs.\n",
    "\n",
    "3. When to use LOOCV?\n",
    "> You can use this technique when your data is limited, and you want to use as much training data as possible when fitting the model. This method is also used because it provides the best error estimate possible for a single new point. Consider that you just ran n-models, where each time you left out a single point. If you are given a single new point and need to estimate your error, leave-one-out-cross-validation is the right method to use. Unfortunately, this method is very computationally expensive. You should be careful using it if you have a lot of data, or if you are planning on testing a lot of different parameter sets. The best way to judge if this method is even possible is to run KFold cross-validation with a large K, maybe 25 or 50, and gauge how long it would take you to actually run Leave-one-out-cross-validation with the n-observations in your data.\n",
    "\n",
    "4. LOOCV Example\n",
    "> Implementing leave-one-out-cross-validation can be done using cross_val_score(). You only need to set the parameter cv equal to the number of observations in your dataset. We can find the number of observations by looking at the shape of the X dataset. The result of running leave-one-out-cross-validation will be a list of errors that stand for the error of running a model and leaving a single point out. The list will have n values, where n is the number of observations. Finally, we print the mean and use this as our overall error metric.\n",
    "\n",
    "5. Let's practice\n",
    "> Let's start practicing leave-one-out-cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d958b8-465c-441c-aa9d-6b82dd54b508",
   "metadata": {},
   "source": [
    "### 4.1. When to use LOOCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266473fd-2b1e-4ade-b435-ef7afe5972f3",
   "metadata": {},
   "source": [
    "Which of the following are reasons you might NOT run LOOCV on the provided `X` dataset? The `X` data has been loaded for you to explore as you see fit.\n",
    "\n",
    "1. The `X` dataset has 122,624 data points, which might be computationally expensive and slow.\n",
    "2. You cannot run LOOCV on classification problems.\n",
    "3. You want to test different values for 15 different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a08841-7dae-4ac7-a370-425c0f18dd15",
   "metadata": {},
   "source": [
    "Possible Answers:\n",
    "- A & B.\n",
    "- B & C.\n",
    "- A & C.\n",
    "- A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ace99a-1fdf-4f75-9ad3-777c6f568c06",
   "metadata": {},
   "source": [
    "> 1 & 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56507c-df0f-4eba-b42e-0b3a967cb271",
   "metadata": {},
   "source": [
    "### 4.2. Leave-one-out-cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43888b62-ddc6-4d4d-a146-640ca476b145",
   "metadata": {},
   "source": [
    "Let's assume your favorite candy is not in the candy dataset, and that you are interested in the popularity of this candy. Using 5-fold cross-validation will train on only 80% of the data at a time. The candy dataset only has 85 rows though, and leaving out 20% of the data could hinder our model. However, using leave-one-out-cross-validation allows us to make the most out of our limited dataset and will give you the best estimate for your favorite candy's popularity!\n",
    "\n",
    "In this exercise, you will use `cross_val_score()` to perform LOOCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a913eae-2e38-4a87-9f1c-1e5d015089ae",
   "metadata": {},
   "source": [
    "- Create a scorer using `mean_absolute_error` for `cross_val_score()` to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "315083d9-a22a-480a-b5c8-308cb0ac89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scoring startegy:\n",
    "mae_scorer = make_scorer(mae, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc5006a-f4d0-4328-b458-63a54d9c7636",
   "metadata": {},
   "source": [
    "- Fill out `cross_val_score()` so that the model `rfr`, the newly defined `mae_scorer`, and LOOCV are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3584154a-5103-495f-9c4f-a86156210e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model:\n",
    "rfr = RandomForestRegressor(n_estimators=15, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2312124-717e-45e4-b3eb-84ea9077dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing 5-fold cross-validation:\n",
    "scores = cross_val_score(estimator=rfr, X=X, y=y, scoring=mae_scorer, cv=len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa229f-6a33-471a-8ed5-47e8d8b4dc0d",
   "metadata": {},
   "source": [
    "- Print the mean and the standard deviation of scores using numpy (loaded as np)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c18fd129-3481-48a2-9a76-5a0daa413a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the errors is: -9.52044832324183.\n",
      "The standard deviation of the errors is: 7.349020637882744.\n"
     ]
    }
   ],
   "source": [
    "# Printing the mean and standard deviation of cross-validation scores:\n",
    "print(f\"The mean of the errors is: {np.mean(scores)}.\")\n",
    "print(f\"The standard deviation of the errors is: {np.std(scores)}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
