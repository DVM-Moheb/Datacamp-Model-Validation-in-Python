{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4109c54c-a494-497a-8dae-eb91c1aafdfb",
   "metadata": {},
   "source": [
    "# Chapter #4: Selecting the Best Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8da3585-a6be-4acd-85b8-db05bfe390fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7a822-8598-4306-a0bf-d45eff7d355f",
   "metadata": {},
   "source": [
    "## 1. Introduction to hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe12e05-02ef-452c-9973-d97f680e71fe",
   "metadata": {},
   "source": [
    "1. Introduction to hyperparameter tuning\n",
    "> Hello again - In this lesson, we are going to start applying the model validation techniques we have been practicing while introducing hyperparameter tuning.\n",
    "\n",
    "2. Model parameters\n",
    "> To start, let's first review what model parameters are, as model parameters and model hyperparameters are quite different. Model parameters are created as the result of fitting a model and are estimated by the input data. They are used to make predictions on new data and are not manually set by the modeler.\n",
    "\n",
    "3. Linear regression parameters\n",
    "> For example, in a linear model, the coefficients and intercept are considered model parameters. We can print a linear model's parameters using lr-dot-coef_ and lr-dot-intercept_. Notice that these parameters are only created after the model has been fit.\n",
    "\n",
    "4. Linear regression parameters\n",
    "> If we did not call .fit, the coefficients and intercept would not exist for the lr object.\n",
    "\n",
    "5. Model hyperparameters\n",
    "> So, if model parameters are the result of training a model, then what are hyperparameters? Hyperparameters are the values that are set before training occurs. So anytime we refer to a parameter as being manually set, we are referring to hyperparameters. We have already been working with some hyperparameters for scikit-learn's random forest models, such as n_estimators, and max_depth. Let's cover a few more of the basic hyperparameters for these models.\n",
    "\n",
    "6. Random forest hyperparameters\n",
    "> The table above only has four of the 15 or so possible hyperparameters, and we have already discussed the first three: n_estimators, max_depth, and max_features during this course. I am adding min_samples_split to our list, which is the minimum number of samples required to make a split at the end of a leaf. If a leaf in a decision tree has four observations in it, min_samples_split must be 4 or greater in order for this leaf to be split into more leaves. So what now? If these are hyperparameters, how do we tune them?\n",
    "\n",
    "7. What is hyperparameter tuning?\n",
    "> Throughout this course, we have been hinting at various aspects of hyperparameter tuning. We have used various hyperparameters and altered the values of these hyperparameters to suit our specific model or data. Hyperparameter tuning consists of selecting hyperparameters to test and then running a specific type of model with various values for these hyperparameters. For each run of the model, we keep track of how well the model did for a specified accuracy metric, as well as keep track of the hyperparameters that were used.\n",
    "\n",
    "8. Specifying ranges\n",
    "> One of the hardest parts of this process is selecting the right hyperparameters to tune, and specifying the appropriate value ranges for each hyperparameter. For example, consider the three ranges of values specified in the example above. When we run hyperparameter tuning, we run our random forest model at different values from the ranges specified. We might select a random max depth, a minimum sample for creating splits of 8, and a maximum feature count of 4. We used the random-dot-choice() function to select randomly from the depth list. To review which parameters were used at any time, you can use the get_params() method on your model.\n",
    "\n",
    "9. Too many hyperparameters!\n",
    "> If you do check out the contents of get_params(), you might feel overwhelmed by the amount of options available. For this model, there are 16 different hyperparameters. In practice, however, only a handful of these hyperparameters will be tuned at the same time. Tuning too many can take forever to train and might make reading the output difficult.\n",
    "\n",
    "10. General guidelines\n",
    "> It's best to start with the basics and tune the hyperparameters you understand. Read through the documentation for the ones that you don't, and test values you have seen in other models. As you practice this technique more, you will become more comfortable with the process.\n",
    "\n",
    "11. Let's practice!\n",
    "> Let's work on the basic steps for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6cd0f0-2c4b-424f-877f-8699404589d8",
   "metadata": {},
   "source": [
    "### 1.1. Creating Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e17ff2-f83b-4d67-9115-adcb9db73521",
   "metadata": {},
   "source": [
    "For a school assignment, your professor has asked your class to create a random forest model to predict the average test score for the final exam.\n",
    "\n",
    "After developing an initial random forest model, you are unsatisfied with the overall accuracy. You realize that there are too many hyperparameters to choose from, and each one has a lot of possible values. You have decided to make a list of possible ranges for the hyperparameters you might use in your next model.\n",
    "\n",
    "Your professor has provided de-identified data for the last ten quizzes to act as the training data. There are 30 students in your class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebbfdc-103d-4c37-ab41-bb3a6f575ea7",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd943f4-7266-4278-af6e-02a22bffcbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the model:\n",
    "rfr = RandomForestRegressor(random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade1194-6dc7-444f-bd0e-970cf10844eb",
   "metadata": {},
   "source": [
    "- Print `.get_params()` in the console to review the possible parameters of the model that you can tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cf0c91-8c76-4c39-85d6-8640c36145ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Printing the model parameters:\n",
    "print(rfr.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658b149-b7af-446d-84ea-06eb80396a18",
   "metadata": {},
   "source": [
    "- Create a maximum depth list, `[4, 8, 12]` and a minimum samples list `[2, 5, 10]` that specify possible values for each hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d79f666-5556-48e1-a7ab-f42ddb36db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for possible values of max_depth & min_samples_split:\n",
    "max_depth = [4, 8, 12]\n",
    "min_samples_split = [2, 5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5633f4-db10-4f28-ba4c-4607fd49316f",
   "metadata": {},
   "source": [
    "- Create one final list to use for the maximum features.\n",
    "> Use values 4 through the maximum number of features possible (10), by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf5b956-3d51-46cc-bd33-73dc4f38b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for possible values of max_features:\n",
    "max_features = [4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a47cf-4cfe-4cbf-9356-5ae0d2740554",
   "metadata": {},
   "source": [
    "### 1.2. Running a model using ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05059d87-fbe6-45e0-b79e-b8d583a7e64d",
   "metadata": {},
   "source": [
    "You have just finished creating a list of hyperparameters and ranges to use when tuning a predictive model for an assignment. You have used `max_depth`, `min_samples_split`, and `max_features` as your range variable names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a2927-55e3-4c56-a9d9-e05212b1232f",
   "metadata": {},
   "source": [
    "- Randomly select a max_depth, min_samples_split, and max_features using your range variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172ef589-5e84-4d57-8fe3-1582b0841190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the default randon number generator:\n",
    "randn_gen = np.random.default_rng(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7188b075-ab83-42bb-bda8-afbaefeb7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting somerandom values for the hyperparameters in question:\n",
    "rfr = RandomForestRegressor(n_estimators=100,\n",
    "                            max_depth=randn_gen.choice(max_depth),\n",
    "                            min_samples_split=randn_gen.choice(min_samples_split),\n",
    "                            max_features=randn_gen.choice(max_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d2be0-d2d0-4b6e-94ed-d7f056f7ccbc",
   "metadata": {},
   "source": [
    "- Print out all of the parameters for rfr to see which values were randomly selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35aaeb8-bf08-4167-a342-85a7d44c60ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 12, 'max_features': 10, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Printing the model parameters:\n",
    "print(rfr.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8e064-aa23-41e4-b958-6737afe0f383",
   "metadata": {},
   "source": [
    "## 2. RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7e2fd-e93d-42f6-8689-231308243873",
   "metadata": {},
   "source": [
    "1. RandomizedSearchCV\n",
    "> Now that we have discussed the basics of hyperparameter tuning let's combine model validation with tuning to start creating the most accurate, validated models possible.\n",
    "\n",
    "2. Grid searching hyperparameters\n",
    "> Consider if we only had two parameters to choose from, the number of trees and the maximum depth. If we had five options for the number of trees and four options for the maximum depth, this would create 20 possible combinations of these parameters. Notice that they form a grid of possible parameters. We could conduct a complete grid search, and run our random forest model using each unique combination of the two hyperparameters.\n",
    "\n",
    "3. Grid searching continued\n",
    "> There is one main benefit for grid searching, which is that each possible combination of values will be tested. However, there is one major drawback: any additional parameter added for testing will grow the training time exponentially. Therefore grid searching is only possible with a limited number of parameters, and a limited number of ranges.\n",
    "\n",
    "4. Better methods\n",
    "> There are two amazing alternatives to using grid search, which both have their advantages over grid searching. Random searching, which consists of randomly selecting from all hyperparameter values from the list of possible ranges, and Bayesian optimization, which uses the past results of each test to update the hyperparameters for the next run. Bayesian approaches are out of the scope for this course, so we will focus on random searching methods.\n",
    "\n",
    "5. Random search\n",
    "> To implement a random search, we can use scikit-learn's method, RandomizedSearchCV(). This method will randomly select hyperparameters for each model run based on the user-defined hyperparameter space. RandomizedSearchCV() requires a dictionary of hyperparameters and their possible values. Here we have specified four max depths, nine max features, and nine min_samples_split options. Using a grid search with these possible parameters would take 324 total model runs,as 4 times 9 times 9 is 324. However, using a random search, we can get similar results only using 30 or 40 runs.\n",
    "\n",
    "6. Random search parameters\n",
    "> To use this method we need to specify a few other parameters. The parameter n_iter specifies the number of models to run. estimator allows us to set the base model, such as a random forest regression model, and scoring allows us to specify a scoring function.\n",
    "\n",
    "7. Setting RandomizedSearchCV parameters\n",
    "> Aside from setting up the parameter distributions, we need to create a model and the scoring function to use. The estimator specified here uses a RandomForestRegression() model, with 20 trees. We have also specified the mean absolute error to be the scoring function.\n",
    "\n",
    "8. RandomizedSearchCV implemented\n",
    "> Let's finally implement the RandomizedSearchCV method. We use our model, rfr, the parameter distribution, specify to use 40 parameter sets and set the cv value to 5. Ah! So hopefully, the \"CV\" on the end of this method helps us see why we are even discussing hyperparameter tuning in a course about model validation! The cross-validation techniques we have been discussing will be used with random searching to help us select the best model for our data. After all, if we test 40 different parameter sets, how do we determine which one is the best? And how do we appropriately compare their results? We have to use the techniques we have learned so far in this course.\n",
    "\n",
    "9. RandomizedSearchCV implemented\n",
    "> After using RandomizedSearchCV, we should have a validated model that has better accuracy than using the base implementation of that model. To actually complete the random search, we use the dot-fit() method, just like any other scikit-learn model.\n",
    "\n",
    "10. Let's explore some examples!\n",
    "> We will save exploring the output of the RandomizedSearchCV() method for the next lesson. For now, let's run through some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e60676-c196-4cb5-ad64-87f4a67b92ed",
   "metadata": {},
   "source": [
    "### 2.1. Preparing for RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802ffff-8fa5-4f52-b2c8-6f185fee411b",
   "metadata": {},
   "source": [
    "Last semester your professor challenged your class to build a predictive model to predict final exam test scores. You tried running a few different models by randomly selecting hyperparameters. However, running each model required you to code it individually.\n",
    "\n",
    "After learning about `RandomizedSearchCV()`, you're revisiting your professors challenge to build the best model. In this exercise, you will prepare the three necessary inputs for completing a random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e982ae1a-9221-4d39-9914-a8eb4a3e3126",
   "metadata": {},
   "source": [
    "- Finalize the parameter dictionary by adding a list for the max_depth parameter with options 2, 4, 6, and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c87b168-e148-4b03-9908-87bc65833c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the param_dist dictionary:\n",
    "param_dist = {\"max_depth\": [2, 4, 6, 8],\n",
    "              \"max_features\": [2, 4, 6, 8, 10],\n",
    "              \"min_samples_split\": [2, 4, 8, 16]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8fcba-621a-4b1b-a427-084bbbf79569",
   "metadata": {},
   "source": [
    "- Create a random forest regression model with ten trees and a random_state of 1111."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb4fdd9-16c0-4b82-b71b-84ea475f7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model:\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e965870-2763-4ff2-8a10-7e1e00a8febd",
   "metadata": {},
   "source": [
    "- Create a mean squared error scorer to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c2323c-6d29-416c-8858-4c9b2b5342dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scoring strategy:\n",
    "scorer = make_scorer(mse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a672a7-fd00-4b1c-84e8-5e4d511ad2c1",
   "metadata": {},
   "source": [
    "## 2.2. Implementing RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc317b9-247f-4682-b042-5ba9f8d9fbea",
   "metadata": {},
   "source": [
    "You are hoping that using a random search algorithm will help you improve predictions for a class assignment. You professor has challenged your class to predict the overall final exam average score.\n",
    "\n",
    "In preparation for completing a random search, you have created:\n",
    "\n",
    "> - `param_dist`: the hyperparameter distributions\n",
    "> - `rfr`: a random forest regression model\n",
    "> -`scorer`: a scoring method to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030ca97-a991-4585-a6a3-ea08cd8845f3",
   "metadata": {},
   "source": [
    "- Load the method for conducting a random search in `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ec78b-3c2a-4686-891f-e811575ce6c3",
   "metadata": {},
   "source": [
    "> Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6133a1b-c7a8-4f91-be7b-e28bb9b5f110",
   "metadata": {},
   "source": [
    "- Complete a random search by filling in the parameters: `estimator`, `param_distributions`, and `scoring`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb7401-9fba-4bdd-a92f-41467e0f3b75",
   "metadata": {},
   "source": [
    "- Use 5-fold cross validation for this random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f416b78e-f70c-481f-9fa7-4932f325307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the randomized search options:\n",
    "random_search = RandomizedSearchCV(estimator=rfr,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   scoring=scorer,\n",
    "                                   cv=5, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d860c5a8-286d-49a4-99b8-d552ddb5b592",
   "metadata": {},
   "source": [
    "## 3. Selecting your final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e77ee0-446c-4401-9e1c-af24f945c8bf",
   "metadata": {},
   "source": [
    "1. Selecting your final model\n",
    "> In this lesson, we will explore the output of a random search implementation and then select, and reuse our final model.\n",
    "\n",
    "2. Random search output\n",
    "> To start, we will assume the variable rs is an implementation of RandomizedSearchCV() that has already been fit on data. Let's explore some of the key attributes of rs. Of course, the first attributes us eager-beavers have to check focuses on the best model. And so, the attributes have been so named best_score_, best_params_, and best_estimator_. These attributes provide the results from the best model found in the random search, and you will use these attributes often.\n",
    "\n",
    "3. Other attributes\n",
    "> Of course, there are other attributes to explore. Perhaps the most useful will be rs-dot-cv_results_, which contains a dictionary full of the cross-validation results. This dictionary includes keys such as \"mean_test_scores,\" which gives the average cross-validation test score for each run. The dictionary also contains the key \"params,\" which contains all of the selected parameters for each model run.\n",
    "\n",
    "4. Using .cv_results_\n",
    "> We can use these attributes to create visuals of the output or make inferences on which hyperparameters are having the biggest impact on the model. For example, let's look at the mean test scores grouped by the maximum depth of the model. Here we grabbed the max depth from each of the 10 models, as well as the mean test score. We then created a pandas DataFrame and grouped the scores by the maximum depth. If we look at the output, a max depth of 2, 4, and even 6 all produced really low scores. However, a max depth of 8 and 10 almost achieved 90% accuracy.\n",
    "\n",
    "5. Other attributes continued\n",
    "> There are a ton of ways to use the cv_results_ output to visualize the effect of each parameter. In the case, we just explored, it's probably best to use a larger max depth when running your models. These results might inspire you to rerun the random search with a slightly different hyperparameter space. Right now, we just want to select the best model from our random search.\n",
    "\n",
    "6. Selecting the best model\n",
    "> However, you perform hyperparameter tuning; in the end, you'll need to select one final model. This may be the model with the best accuracy or the model with the highest precision or even recall. For now, let's assume we are going for the best mean squared error. The model with the lowest error from the cross-validation is our guess for the model that will perform the best on future data. The best_estimator_ attribute contains the model that performed the best during cross-validation.\n",
    "\n",
    "7. Comparing types of models\n",
    "> As an aside, if you built different types of models, say a random forest and a gradient boosting model, you can test the accuracies of your final models on the test set that you held out. This gives an unbiased estimate and can help you make your final overall decision. In the case above, you would select the gradient boosting model as the final model because it had a lower mean squared error on the test data.\n",
    "\n",
    "8. Using .best_estimator_\n",
    "> Let's use best_estimator_ from a random forest model. You can use the method predict() on this estimator with new data just like any other scikit-learn model. You can check all of the parameters that were used by calling the get_params() method or you can save the estimator as a pickle file using the joblib module for reuse later. This will allow you to load your model on a later date or to share your model with a colleague.\n",
    "\n",
    "9. Let's practice!\n",
    "> Let's work through a couple examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc2189-233f-4e37-bf76-0819057bb5a1",
   "metadata": {},
   "source": [
    "### 3.1. Best classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a657bec-504c-49d5-bce6-e11f4992e0ed",
   "metadata": {},
   "source": [
    "You are in a competition at work to build the best model for predicting the winner of a Tic-Tac-Toe game. You already ran a random search and saved the results of the most accurate model to `rs`.\n",
    "\n",
    "Which parameter set produces the best classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a5a1bf-8b09-4270-9673-2fae5150ad50",
   "metadata": {},
   "source": [
    "Possible Answers:\n",
    "- `{'max_depth': 8, 'min_samples_split': 4, 'n_estimators': 10}`.\n",
    "- `{'max_depth': 2, 'min_samples_split': 4, 'n_estimators': 10}`.\n",
    "- `{'max_depth': 12, 'min_samples_split': 4, 'n_estimators': 20}`.\n",
    "- `{'max_depth': 2, 'min_samples_split': 2, 'n_estimators': 50}`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0026b-455e-4bb6-a5be-e6035d8fb493",
   "metadata": {},
   "source": [
    "> `{'max_depth': 12, 'min_samples_split': 4, 'n_estimators': 20}`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911f7c8-421d-4db0-b52e-230b310bb57f",
   "metadata": {},
   "source": [
    "### 3.2. Selecting the best precision model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da79a83-fa0d-4f49-9ca2-3da9492cdf67",
   "metadata": {},
   "source": [
    "Your boss has offered to pay for you to see three sports games this year. Of the 41 home games your favorite team plays, you want to ensure you go to three home games that they will definitely win. You build a model to decide which games your team will win.\n",
    "\n",
    "To do this, you will build a random search algorithm and focus on model precision (to ensure your team wins). You also want to keep track of your best model and best parameters, so that you can use them again next year (if the model does well, of course). You have already decided on using the random forest classification model `rfc` and generated a parameter distribution `param_dist`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c814c707-b23a-4e34-89f7-7f9a8366eaba",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4443946d-2552-426f-aaa4-8035594740a6",
   "metadata": {},
   "source": [
    "> This data isn't available outside the workspace, so I will use the `tic_tic_toe` data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d9711d5-c5ab-409a-a0e0-6c59bfceb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data:\n",
    "tic_tac_toe = pd.read_csv(\"./data/tic-tac-toe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fca9ddb9-0594-4e94-a7ee-5cbcecdfb539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data shape:\n",
    "tic_tac_toe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee8336a-3d10-4cb0-9421-22066467a75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-Left</th>\n",
       "      <th>Top-Middle</th>\n",
       "      <th>Top-Right</th>\n",
       "      <th>Middle-Left</th>\n",
       "      <th>Middle-Middle</th>\n",
       "      <th>Middle-Right</th>\n",
       "      <th>Bottom-Left</th>\n",
       "      <th>Bottom-Middle</th>\n",
       "      <th>Bottom-Right</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n",
       "0        x          x         x           x             o            o   \n",
       "1        x          x         x           x             o            o   \n",
       "2        x          x         x           x             o            o   \n",
       "3        x          x         x           x             o            o   \n",
       "4        x          x         x           x             o            o   \n",
       "\n",
       "  Bottom-Left Bottom-Middle Bottom-Right     Class  \n",
       "0           x             o            o  positive  \n",
       "1           o             x            o  positive  \n",
       "2           o             o            x  positive  \n",
       "3           o             b            b  positive  \n",
       "4           b             o            b  positive  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the first 5 rows:\n",
    "tic_tac_toe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89e64a64-3672-4716-8b78-25bf415aa649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the target column into (0 / 1):\n",
    "tic_tac_toe['Class'] = tic_tac_toe['Class'].apply(lambda x : 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "990804d5-1804-440e-824a-e06c32745c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the feaatures into (0 / 1):\n",
    "features = [col for col in tic_tac_toe.columns if col != 'Class']\n",
    "tic_tac_toe = pd.get_dummies(data=tic_tac_toe, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2aa7185-3487-43a6-b11e-feea629d7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to split the data into X & y:\n",
    "def split_data(data, y_col):\n",
    "    \n",
    "    features = [col for col in data.columns if col != y_col]\n",
    "    \n",
    "    X = data[features].copy()\n",
    "    y = data[y_col].copy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d87ae1-114f-4756-9167-c9d8ad2e7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slpitting the data into features matrix (X) & target column (y):\n",
    "X, y = split_data(tic_tac_toe, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "305ca3fc-3a5c-436e-9719-cc11ff7d7f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training & hold-out sets:\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4db80af8-7f5d-4b81-b633-b22ea5dd3582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model:\n",
    "rfc = RandomForestClassifier(random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651bf22-5793-455b-93d0-b08806d95f7c",
   "metadata": {},
   "source": [
    "- Create a precision scorer, `precision` using `make_scorer(<scoring_function>)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d82df37e-06bb-465f-afd6-33d1553ecbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scoring strategy:\n",
    "precision = make_scorer(precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226c958-dd27-4221-8c11-ce2de314deee",
   "metadata": {},
   "source": [
    "- Complete the random search method by using `rfc` and param_dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "736eafaf-7a67-4f7d-957b-03651181199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the RandomizedSearchCV object:\n",
    "rs = RandomizedSearchCV(estimator=rfc,\n",
    "                        param_distributions=param_dist,\n",
    "                        scoring=precision,\n",
    "                        cv=5, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ac353af-3ef3-410a-affa-e724d9657e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1111),\n",
       "                   param_distributions={'max_depth': [2, 4, 6, 8],\n",
       "                                        'max_features': [2, 4, 6, 8, 10],\n",
       "                                        'min_samples_split': [2, 4, 8, 16]},\n",
       "                   random_state=1111, scoring=make_scorer(precision_score))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RandomizedSearchCV object:\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d851cf-ddd7-43a7-b41c-1b22644ca94b",
   "metadata": {},
   "source": [
    "- Use `rs.cv_results_` to print the mean test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0c1cf8f-2cdb-4a3f-be82-d2a533fbc504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for each run was: [0.85, 0.78, 0.72, 0.93, 0.77, 0.9, 0.78, 0.9, 0.72, 0.97].\n"
     ]
    }
   ],
   "source": [
    "# Printing the mean test scores:\n",
    "print(f\"The score for each run was: {[round(s, 2) for s in rs.cv_results_['mean_test_score']]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3299df-823a-45bf-a6b0-3a58181febc5",
   "metadata": {},
   "source": [
    "- Print the best overall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7674912c-25b3-4347-98b6-af748c777ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score for a single model was: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Printing the best model score:\n",
    "print(f\"The best score for a single model was: {rs.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd5805-6ea8-4966-8d98-2816e6f7505e",
   "metadata": {},
   "source": [
    "- Print the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5786b1-a243-400c-bccf-5921eb129ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters were: {'min_samples_split': 2, 'max_features': 8, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "# Printing the best parameters:\n",
    "print(f\"The best parameters were: {rs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a10b9-26fe-480a-9683-6a16dbc75ade",
   "metadata": {},
   "source": [
    "- Evaluate the best model performance on the hold-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6398d6a6-62cc-4eb0-bb38-1c224841c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions necessary for evaluating model performance:\n",
    "y_pred = rs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd158ba9-fdcf-4c6c-b8c1-f7cc99d3f172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision score for the best model on hold-out set was: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model performance on the hold-out set:\n",
    "best_model_precision = round(precision_score(y_test, y_pred), 2)\n",
    "print(f\"The precision score for the best model on hold-out set was: {best_model_precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82909a0d-9cd0-4411-8bf7-cf614512da33",
   "metadata": {},
   "source": [
    "- Explore the scores for different values of the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e715dfef-764d-454e-915f-4290250c5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an array for each parameter values:\n",
    "min_samples_split_array = [p['min_samples_split'] for p in rs.cv_results_['params']]\n",
    "max_features_array = [p['max_features'] for p in rs.cv_results_['params']]\n",
    "max_depth_array = [p['max_depth'] for p in rs.cv_results_['params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d29c4250-7497-406d-a15f-b9582e1bca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an array of scores:\n",
    "mean_scores = [round(s, 2) for s in rs.cv_results_['mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "166491f2-6b0c-454b-8cd7-c13143ab9a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_samples_split  max_features  max_depth  scores\n",
       "0                  8             6          6    0.85\n",
       "1                 16            10          4    0.78\n",
       "2                 16            10          2    0.72\n",
       "3                  8            10          6    0.93\n",
       "4                  4             8          4    0.77"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organizing the model runs into a dataframe:\n",
    "scores_df = pd.DataFrame({'min_samples_split': min_samples_split_array,\n",
    "                          'max_features': max_features_array,\n",
    "                          'max_depth': max_depth_array,\n",
    "                          'scores': mean_scores})\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbe8c725-8935-4983-ac88-f233f3b9ed3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making inference about max_depth:\n",
    "scores_df.groupby(by='max_depth')['scores'].mean().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5dab2-704c-424c-a3de-3db331e3d813",
   "metadata": {},
   "source": [
    "## 4. Course completed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467aaf7-5124-4857-a24d-84b6b8be4ff0",
   "metadata": {},
   "source": [
    "1. Course completed!\n",
    "> Thank you for sticking with me through these four chapters and congratulations on completing this course on model validation!\n",
    "\n",
    "2. Course recap\n",
    "> We covered topics such as evaluation metrics, creating training, validation, and testing datasets, cross-validation, and even touched on model tuning. You can use these techniques going forward to make sure your models perform as expected on new data.\n",
    "\n",
    "3. Next steps\n",
    "> There are so many directions that you can go from here. One of the best ways that you can solidify your model validation understanding would be to work through an older Kaggle competition. These are modeling competitions where several people post modeling code and techniques. Working through their examples would solidify all that you have learned here.\n",
    "\n",
    "4. Next steps\n",
    "> There are also plenty of other DataCamp courses you can check out. If you want a deeper dive into model tuning, check out our course on hyperparameter tuning. Or if you want to start using more complex models, beyond the random forests we used in this course, check out our course on deep learning.\n",
    "\n",
    "5. Thank you!\n",
    "> Again - Thank you for joining me and good luck in your future modeling efforts!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
